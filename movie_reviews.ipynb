{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Super Heroes - Python, Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install Selenium and Scrapy\n",
    "\n",
    "-   Selenium: to load the reviews.\n",
    "-   Scrapy: to extract the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /usr/local/python/3.10.8/lib/python3.10/site-packages (4.14.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /home/codespace/.local/lib/python3.10/site-packages (from selenium) (2.0.6)\n",
      "Requirement already satisfied: trio~=0.17 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/codespace/.local/lib/python3.10/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/python/3.10.8/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /usr/local/python/3.10.8/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /home/codespace/.local/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting scrapy\n",
      "  Obtaining dependency information for scrapy from https://files.pythonhosted.org/packages/08/66/22ed9609df4b6d94a66512572a11b35943a6cb36dc268f88ebfbede60be1/Scrapy-2.11.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading Scrapy-2.11.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting Twisted<23.8.0,>=18.9.0 (from scrapy)\n",
      "  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scrapy) (41.0.4)\n",
      "Collecting cssselect>=0.9.1 (from scrapy)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting itemloaders>=1.0.1 (from scrapy)\n",
      "  Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
      "Collecting parsel>=1.5.0 (from scrapy)\n",
      "  Downloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting pyOpenSSL>=21.0.0 (from scrapy)\n",
      "  Obtaining dependency information for pyOpenSSL>=21.0.0 from https://files.pythonhosted.org/packages/f0/e2/f8b4f1c67933a4907e52228241f4bd52169f3196b70af04403b29c63238a/pyOpenSSL-23.2.0-py3-none-any.whl.metadata\n",
      "  Downloading pyOpenSSL-23.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting queuelib>=1.4.2 (from scrapy)\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting service-identity>=18.1.0 (from scrapy)\n",
      "  Obtaining dependency information for service-identity>=18.1.0 from https://files.pythonhosted.org/packages/0c/42/bf07f277b45da6e350df3314804aa2b5411e0938d3b78b4f17da2e1302c2/service_identity-23.1.0-py3-none-any.whl.metadata\n",
      "  Downloading service_identity-23.1.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Obtaining dependency information for w3lib>=1.17.0 from https://files.pythonhosted.org/packages/82/e2/dcf8573d7153194eb673347cea1f9bbdb2a8e61030740fb6f50e4234a00b/w3lib-2.1.2-py3-none-any.whl.metadata\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting zope.interface>=5.1.0 (from scrapy)\n",
      "  Obtaining dependency information for zope.interface>=5.1.0 from https://files.pythonhosted.org/packages/4f/20/94d4f221989b4bbdd09004b2afb329958e776b7015b7ea8bc915327e195a/zope.interface-6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading zope.interface-6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protego>=0.1.15 (from scrapy)\n",
      "  Obtaining dependency information for protego>=0.1.15 from https://files.pythonhosted.org/packages/bc/16/14fd1ecdece2e1d87279fc09fbd2d55bae5fa033783c3547af631c74d718/Protego-0.3.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading Protego-0.3.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting itemadapter>=0.1.0 (from scrapy)\n",
      "  Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.8/lib/python3.10/site-packages (from scrapy) (68.0.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from scrapy) (23.2)\n",
      "Collecting tldextract (from scrapy)\n",
      "  Obtaining dependency information for tldextract from https://files.pythonhosted.org/packages/75/c0/038a9529d1b3cf10ab682bb66e2e253530e5380c2b656205703d9f618b30/tldextract-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading tldextract-5.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting lxml>=4.4.1 (from scrapy)\n",
      "  Obtaining dependency information for lxml>=4.4.1 from https://files.pythonhosted.org/packages/3c/d2/11533f0bc47ff4d828a20cfb702f3453fe714bd5b475fcdc8cec6e6b7dcf/lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/codespace/.local/lib/python3.10/site-packages (from cryptography>=36.0.0->scrapy) (1.16.0)\n",
      "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (23.1.0)\n",
      "Collecting pyasn1 (from service-identity>=18.1.0->scrapy)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1-modules (from service-identity>=18.1.0->scrapy)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting constantly>=15.1 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting incremental>=21.3.0 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Automat>=0.8.0 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting hyperlink>=17.1.1 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /home/codespace/.local/lib/python3.10/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (4.8.0)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.10/site-packages (from tldextract->scrapy) (3.4)\n",
      "Requirement already satisfied: requests>=2.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /home/codespace/.local/lib/python3.10/site-packages (from tldextract->scrapy) (3.12.4)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from Automat>=0.8.0->Twisted<23.8.0,>=18.9.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (2023.7.22)\n",
      "Downloading Scrapy-2.11.0-py2.py3-none-any.whl (286 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.4/286.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Protego-0.3.0-py2.py3-none-any.whl (8.5 kB)\n",
      "Downloading pyOpenSSL-23.2.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading service_identity-23.1.0-py3-none-any.whl (12 kB)\n",
      "Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading zope.interface-6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.1/247.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tldextract-5.0.1-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyDispatcher, incremental, constantly, zope.interface, w3lib, queuelib, pyasn1, protego, lxml, jmespath, itemadapter, hyperlink, cssselect, Automat, Twisted, requests-file, pyasn1-modules, parsel, tldextract, service-identity, pyOpenSSL, itemloaders, scrapy\n",
      "Successfully installed Automat-22.10.0 PyDispatcher-2.0.7 Twisted-22.10.0 constantly-15.1.0 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 lxml-4.9.3 parsel-1.8.1 protego-0.3.0 pyOpenSSL-23.2.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.11.0 service-identity-23.1.0 tldextract-5.0.1 w3lib-2.1.2 zope.interface-6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium\n",
    "! pip install scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Dowload Chrome Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scrapy.selector import Selector\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Selenium test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'capabilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py:38\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     path \u001b[39m=\u001b[39m SeleniumManager()\u001b[39m.\u001b[39;49mdriver_location(options) \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[1;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/selenium/webdriver/common/selenium_manager.py:79\u001b[0m, in \u001b[0;36mSeleniumManager.driver_location\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Determines the path of the correct driver.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[39m:Args:\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39m - browser: which browser to get the driver path for.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39m:Returns: The driver path to use\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m browser \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39;49mcapabilities[\u001b[39m\"\u001b[39m\u001b[39mbrowserName\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     81\u001b[0m args \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_binary()), \u001b[39m\"\u001b[39m\u001b[39m--browser\u001b[39m\u001b[39m\"\u001b[39m, browser]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/BizzSummit/movie_reviews.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bzany-disco-5prxxrv5qwfvjjp/workspaces/BizzSummit/movie_reviews.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome(\u001b[39m'\u001b[39;49m\u001b[39mchromedriver.exe\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bzany-disco-5prxxrv5qwfvjjp/workspaces/BizzSummit/movie_reviews.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://www.imdb.com/title/tt15398776/reviews/?ref_=tt_ql_2\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bzany-disco-5prxxrv5qwfvjjp/workspaces/BizzSummit/movie_reviews.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     42\u001b[0m service \u001b[39m=\u001b[39m service \u001b[39mif\u001b[39;00m service \u001b[39melse\u001b[39;00m Service()\n\u001b[1;32m     43\u001b[0m options \u001b[39m=\u001b[39m options \u001b[39mif\u001b[39;00m options \u001b[39melse\u001b[39;00m Options()\n\u001b[0;32m---> 45\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     46\u001b[0m     DesiredCapabilities\u001b[39m.\u001b[39;49mCHROME[\u001b[39m\"\u001b[39;49m\u001b[39mbrowserName\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     47\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mgoog\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     48\u001b[0m     options,\n\u001b[1;32m     49\u001b[0m     service,\n\u001b[1;32m     50\u001b[0m     keep_alive,\n\u001b[1;32m     51\u001b[0m )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/selenium/webdriver/chromium/webdriver.py:51\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvendor_prefix \u001b[39m=\u001b[39m vendor_prefix\n\u001b[1;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice \u001b[39m=\u001b[39m service\n\u001b[0;32m---> 51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m DriverFinder\u001b[39m.\u001b[39;49mget_path(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mservice, options)\n\u001b[1;32m     53\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     55\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py:40\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     38\u001b[0m     path \u001b[39m=\u001b[39m SeleniumManager()\u001b[39m.\u001b[39mdriver_location(options) \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[1;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m---> 40\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to obtain driver for \u001b[39m\u001b[39m{\u001b[39;00moptions\u001b[39m.\u001b[39;49mcapabilities[\u001b[39m'\u001b[39m\u001b[39mbrowserName\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m using Selenium Manager.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m     \u001b[39mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m Path(path)\u001b[39m.\u001b[39mis_file():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "url = 'https://www.imdb.com/title/tt15398776/reviews/?ref_=tt_ql_2'\n",
    "time.sleep(1)\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "print(driver.title)\n",
    "time.sleep(1)\n",
    "body = driver.find_element(By.CSS_SELECTOR, 'body')\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "time.sleep(1)\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "time.sleep(1)\n",
    "body.send_keys(Keys.PAGE_DOWN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Extract the review count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3192'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use scrapy Selector to extract this information\n",
    "sel = Selector(text = driver.page_source)\n",
    "# pass the HTML code of the page to Scrapy Selector and extract the total review count.\n",
    "review_counts = sel.css('.lister .header span::text').extract_first().replace('.','').split(' ')[0]\n",
    "\n",
    "review_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Load all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:04<00:00, 29.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_review_pages = int(int(review_counts)/25)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in tqdm(range(more_review_pages)):\n",
    "    try:\n",
    "        css_selector = 'load-more-trigger'\n",
    "        driver.find_element(By.ID, css_selector).click()\n",
    "        counter = counter + 1\n",
    "    except:\n",
    "        counter = counter + 1\n",
    "        pass\n",
    "    \n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Extract Review from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nreview_title: Murphy is exceptional\n",
      "nreview_rating: 9\n",
      "nreview_date: 19 July 2023\n",
      "nreview: You'll have to have your wits about you and your brain fully switched on watching Oppenheimer as it could easily get away from a nonattentive viewer. This is intelligent filmmaking which shows it's audience great respect. It fires dialogue packed with information at a relentless pace and jumps to very different times in Oppenheimer's life continuously through it's 3 hour runtime. There are visual clues to guide the viewer through these times but again you'll have to get to grips with these quite quickly. This relentlessness helps to express the urgency with which the US attacked it's chase for the atomic bomb before Germany could do the same. An absolute career best performance from (the consistenly brilliant) Cillian Murphy anchors the film. This is a nailed on Oscar performance. In fact the whole cast are fantastic (apart maybe for the sometimes overwrought Emily Blunt performance). RDJ is also particularly brilliant in a return to proper acting after his decade or so of calling it in. The screenplay is dense and layered (I'd say it was a thick as a Bible), cinematography is quite stark and spare for the most part but imbued with rich, lucious colour in moments (especially scenes with Florence Pugh), the score is beautiful at times but mostly anxious and oppressive, adding to the relentless pacing. The 3 hour runtime flies by. All in all I found it an intense, taxing but highly rewarding watch. This is film making at it finest. A really great watch.\n"
     ]
    }
   ],
   "source": [
    "# We can now extract the review information from the page source.\n",
    "sel2 = Selector(text = driver.page_source)\n",
    "rating = sel2.css('.review-container .rating-other-user-rating span::text').extract_first().strip()\n",
    "review = sel2.css('.text.show-more__control::text').extract_first().strip()\n",
    "review_date = sel2.css('.review-date::text').extract_first().strip()\n",
    "review_title = sel2.css('a.title::text').extract_first().strip()\n",
    "review_url = sel2.css('a.title::attr(href)').extract_first().strip()\n",
    "\n",
    "print('nreview_title:',review_title)\n",
    "print('nreview_rating:',rating)\n",
    "print('nreview_date:',review_date)\n",
    "print('nreview:',review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's nothing like the first in a series, is there? The introduction to the characters, the immersion into the fictional world, the first time you laugh, cry, care, and fear for someone's safety can never be repeated. No matter how many Harry Potter movies they crank out, or if they ever remake them in the future, none will come close to the wonderful first film, Harry Potter and the Sorcerer's Stone.\n",
      "I'm sure everyone has their own childhood memories of reading the Harry Potter books that they'll tell their grandkids about, but I'll never forget going to see the first movie in the theaters. The lights dimmed, John Williams's perfect theme played its first notes as Richard Harris walked down Privet Drive, and everyone in the theater was transported to another world. John Williams's numerous themes, all wonderful and a personification of the wizarding world, took the early movies to another level. As other composers tried their hands at the later films, that quality was missing. There's something truly special about going to see this movie on the big screen, and while the \"magical\" qualities might not all be credited to the music, it's certainly one of them.\n",
      "Welcome to the world of Harry Potter, where if you're a ten-year-old kid who doesn't fit in, you might get a letter delivered by an owl telling you you have magical powers and should go to a special school to hone them. Believe it or not, there are people who watch this movie without reading the books, so a bit of description is necessary. Obviously the stars of the show are the children, who were selected out of millions of other kids to be able to memorize lines, not look in the camera, endear themselves to worldwide audiences, and hopefully act. Daniel Radcliffe, Emma Watson, Rupert Grint, and Tom Felton are so cute and tiny in this first movie, you'll undoubtedly find yourself re-watching it as the years pass just to see them as kids again. I always marvel that child actors train themselves not to look in the camera, so even if their performances aren't perfect, I cut them slack, knowing firsthand how hard it is. And these kids had to dress in funny costumes, recite incantations without laughing, and pretend they're looking at things that were added in post production!\n",
      "Usually, in kids' movies, there's a grown-up or two who add to the cast and make the adult audience members feel less silly that they're watching it. In the Harry Potter movies, everyone wanted to be in them! Throughout the series you'll see a host of familiar faces as \"guest stars\" but the regulars will make special places in your heart. Richard Harris, Maggie Smith, Alan Rickman, and Robbie Coltrane are household names for little kids, because they're so convincing as the kindhearted Dumbledore, the wizened but sentimental McGonagall, the endlessly mimicable Snape, and the jolly Hagrid, kids today can't imagine they've had any other career prior to these movies! Is there any kid who doesn't immediately attribute the word \"earwax\" to Richard Harris, point out striped cats as \"Maggie Smith cats\", mumble \"Shouldn't have said that,\" when they make a mistake, or practice putting pauses in their sentences like Alan Rickman?\n",
      "First movies are so special, since they introduce audiences to a world that will hopefully capture their attention for however many more movies will be made. In J.K. Rowling's fantasy world, there's so much to fall in love with; and in the film adaptation you can really believe it exists. Seeing the Hogwarts structure for the first time creates a special feeling in your heart that can only be recaptured by watching the movie again or going to see the next in the series. The Great Hall, Quidditch, the Sorting Hat, talking portraits, flying lessons, selecting the perfect wand-all these Harry Potter moments are perfectly recreated in the first of a series that saw an entire generation grow up buying toy wands and trying Bertie Bott's Every Flavor Beans.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from scrapy import Selector\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "url = 'https://www.imdb.com/title/tt0241527/reviews?ref_=tt_sa_3'\n",
    "driver.get(url)\n",
    "\n",
    "# Scroll down to load more reviews\n",
    "for _ in range(3):\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Extract the review count and calculate the number of pages\n",
    "sel = Selector(text=driver.page_source)\n",
    "review_counts = int(sel.css('.lister .header span::text').re_first(r'\\d+').replace(',', ''))\n",
    "more_review_pages = (review_counts // 25) + 1\n",
    "\n",
    "# Click the \"Load More\" button to load additional reviews\n",
    "for i in tqdm(range(more_review_pages)):\n",
    "    try:\n",
    "        driver.find_element(By.CLASS_NAME, 'load-more-trigger').click()\n",
    "        time.sleep(2)  # Add a slight delay after clicking the button\n",
    "    except:\n",
    "        break  # Break if there are no more reviews to load\n",
    "\n",
    "# Extract the review content\n",
    "reviews = sel.css('.lister-item-content .text::text').extract()\n",
    "\n",
    "# Print the first few reviews as an example\n",
    "len(reviews)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Extract info for all the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:02<00:00, 66.25it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rating_list = []\n",
    "review_date_list = []\n",
    "review_title_list = []\n",
    "author_list = []\n",
    "review_list = []\n",
    "review_url_list = []\n",
    "error_url_list = []\n",
    "error_msg_list = []\n",
    "reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
    "for d in tqdm(reviews):\n",
    "    try:\n",
    "        sel2 = Selector(text = d.get_attribute('innerHTML'))\n",
    "        try:\n",
    "            rating = sel2.css('.rating-other-user-rating span::text').extract_first()\n",
    "        except:\n",
    "            rating = np.NaN\n",
    "        try:\n",
    "            review = sel2.css('.text.show-more__control::text').extract_first()\n",
    "        except:\n",
    "            review = np.NaN\n",
    "        try:\n",
    "            review_date = sel2.css('.review-date::text').extract_first()\n",
    "        except:\n",
    "            review_date = np.NaN    \n",
    "        try:\n",
    "            author = sel2.css('.display-name-link a::text').extract_first()\n",
    "        except:\n",
    "            author = np.NaN    \n",
    "        try:\n",
    "            review_title = sel2.css('a.title::text').extract_first()\n",
    "        except:\n",
    "            review_title = np.NaN\n",
    "        try:\n",
    "            review_url = sel2.css('a.title::attr(href)').extract_first()\n",
    "        except:\n",
    "            review_url = np.NaN\n",
    "        rating_list.append(rating)\n",
    "        review_date_list.append(review_date)\n",
    "        review_title_list.append(review_title)\n",
    "        author_list.append(author)\n",
    "        review_list.append(review)\n",
    "        review_url_list.append(review_url)\n",
    "    except Exception as e:\n",
    "        error_url_list.append(url)\n",
    "        error_msg_list.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Create a pandas DataFrame with each extracted review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review_Url</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19 July 2023</td>\n",
       "      <td>9</td>\n",
       "      <td>Murphy is exceptional\\n</td>\n",
       "      <td>/review/rw9199470/?ref_=tt_urv</td>\n",
       "      <td>You'll have to have your wits about you and yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20 July 2023</td>\n",
       "      <td>8</td>\n",
       "      <td>A challenging watch to be sure, but a worthwh...</td>\n",
       "      <td>/review/rw9202448/?ref_=tt_urv</td>\n",
       "      <td>One of the most anticipated films of the year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20 July 2023</td>\n",
       "      <td>10</td>\n",
       "      <td>A brilliantly layered examination of a man th...</td>\n",
       "      <td>/review/rw9202246/?ref_=tt_urv</td>\n",
       "      <td>\"Oppenheimer\" is a biographical thriller film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20 July 2023</td>\n",
       "      <td>10</td>\n",
       "      <td>Nolan delivers a powerfull biopic that shows ...</td>\n",
       "      <td>/review/rw9202357/?ref_=tt_urv</td>\n",
       "      <td>This movie is just... wow! I don't think I hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26 July 2023</td>\n",
       "      <td>8</td>\n",
       "      <td>Nolan touches greatness, falls slightly short\\n</td>\n",
       "      <td>/review/rw9216587/?ref_=tt_urv</td>\n",
       "      <td>I was familiar with the Manhattan project and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Review_Date Rating                                       Review_Title  \\\n",
       "0  19 July 2023      9                            Murphy is exceptional\\n   \n",
       "1  20 July 2023      8   A challenging watch to be sure, but a worthwh...   \n",
       "2  20 July 2023     10   A brilliantly layered examination of a man th...   \n",
       "3  20 July 2023     10   Nolan delivers a powerfull biopic that shows ...   \n",
       "4  26 July 2023      8    Nolan touches greatness, falls slightly short\\n   \n",
       "\n",
       "                       Review_Url  \\\n",
       "0  /review/rw9199470/?ref_=tt_urv   \n",
       "1  /review/rw9202448/?ref_=tt_urv   \n",
       "2  /review/rw9202246/?ref_=tt_urv   \n",
       "3  /review/rw9202357/?ref_=tt_urv   \n",
       "4  /review/rw9216587/?ref_=tt_urv   \n",
       "\n",
       "                                              Review  \n",
       "0  You'll have to have your wits about you and yo...  \n",
       "1  One of the most anticipated films of the year ...  \n",
       "2  \"Oppenheimer\" is a biographical thriller film ...  \n",
       "3  This movie is just... wow! I don't think I hav...  \n",
       "4  I was familiar with the Manhattan project and ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe from the lists of reviews, ratings, titles and dates.\n",
    "\n",
    "review_df = pd.DataFrame({\n",
    "    'Review_Date':review_date_list,\n",
    "    'Rating':rating_list,\n",
    "    'Review_Title':review_title_list,\n",
    "    'Review_Url':review_url_list,\n",
    "    'Review':review_list\n",
    "    })\n",
    "\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Save the content of the DataFrame in a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file.\n",
    "\n",
    "review_df.to_csv('movie_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review_Date     0\n",
       "Rating          7\n",
       "Review_Title    0\n",
       "Review_Url      0\n",
       "Review          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are nan values in the dataframe.\n",
    "\n",
    "review_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are duplicate reviews in the dataframe.\n",
    "\n",
    "review_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review_Date     object\n",
       "Rating          object\n",
       "Review_Title    object\n",
       "Review_Url      object\n",
       "Review          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types of the dataframe.\n",
    "review_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_df = pd.read_csv('movie_reviews.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
